---
toc: true
toc_label: "Table of Contents"
toc_icon: "cog"
toc_sticky: true

layout: post-with-comments
title: '[AAAI`18] FiLM: Visual Reasoning with a General Conditioning Layer'
excerpt: "FiLM: Visual Reasoning with a General Conditioning Layer"
date: 2024-02-08
last_modified_at: 2024-02-08
categories:
  - deep_learning-paper_review
tags: 
  - [Visual Reasoning, Conditioning, Visual-Language Model(VLM)]

use_math: true
comments: true
share : false
---



<img src="/home/dshong/git/dazory.github.io/resources/film_visual_reasoning_with_a_general_conditioning_layer/film.png" alt="Untitled (2)" style="zoom:67%;" />



ë³¸ ì—°êµ¬ì˜ ì£¼ìš” taskëŠ” visual reasoningìœ¼ë¡œ, CLEVR benchmarkì—ì„œ ì œì•ˆëœ ë°©ë²•ì˜ íš¨ê³¼ë¥¼ ê²€ì¦í•˜ì˜€ë‹¤.

> **CLEVR benchmarkë€?**
>
> ![clevr_benchmark](/home/dshong/git/dazory.github.io/resources/film_visual_reasoning_with_a_general_conditioning_layer/clevr_benchmark.png)
>
> <img src="/home/dshong/git/dazory.github.io/resources/film_visual_reasoning_with_a_general_conditioning_layer/clevr_benchmark2.png" alt="img" style="zoom:67%;" />
>
> - Question answeringì„ í†µí•´ visual reasoning ì„±ëŠ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ë²¤ì¹˜ë§ˆí¬
>
> - ì´ë¯¸ì§€ëŠ” ì„œë¡œ ë‹¤ë¥¸ ì„±ì§ˆ(e.g. ëª¨ì–‘, ì¬ë£Œ, ìƒ‰ìƒ, í¬ê¸°)ì„ ê°–ëŠ” 3D-rendered objectsë¡œ êµ¬ì„±ëœë‹¤.
>
> - ì§ˆë¬¸ì€ ì—¬ëŸ¬ ë‹¨ê³„ì— ê±¸ì³ êµ¬ì„±ë¨ (ë³µì¡í•¨)
>
>   E.g. â€œHow many green objects have the same size as the green metallic block?â€
>
> - ì‹œê°ìë£Œ(image)ì™€ ì§ˆë¬¸(text)ì´ ì£¼ì–´ì¡Œì„ ë•Œ, ì‹œê° ìë£Œì— ê¸°ë°˜í•˜ì—¬ ì§ˆë¬¸ì— ë‹µ(text)í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•¨



![data_bias](/home/dshong/git/dazory.github.io/resources/film_visual_reasoning_with_a_general_conditioning_layer/data_bias.png)

ì €ìëŠ” ê¸°ì¡´ ë°©ì‹ë“¤ì´ ë³µì¡í•œ ê¸°ë³¸ êµ¬ì¡°ë¥¼ í¬ì°©í•˜ê¸° ë³´ë‹¨ ë°ì´í„° í¸í–¥ì„ ì´ìš©í•˜ëŠ” ê²½í–¥ì´ ìˆë‹¤ëŠ” ë…¼ë¬¸ì„ ì¸ìš©í•˜ì˜€ë‹¤. ê·¸ëŸ¬ë©´ì„œ í•™ìŠµ ë°ì´í„°ì— í¸í–¥í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ë°ì´í„°ì— ë‚´ì¬ëœ êµ¬ì¡° ìì²´ë¥¼ í•™ìŠµí•˜ëŠ” ë°©ë²•ìœ¼ë¡œ FiLMì„ ì œì•ˆí•œë‹¤.



## Method

![introduction_film](/home/dshong/git/dazory.github.io/resources/film_visual_reasoning_with_a_general_conditioning_layer/introduction_film.png)

**FiLM (Feature-wise Linear Modulation)**ì€ ì„ì˜ì˜ ì…ë ¥ì„ ì´ìš©í•˜ì—¬ $\gamma$,$\beta$ë¼ëŠ” conditioning vectorë¥¼ ìƒì„±í•˜ê³ , ì´ë¥¼ ì´ìš©í•˜ì—¬ ì£¼ì–´ì§„ ì…ë ¥ì— ëŒ€í•´ affine transformation $\gamma_{i,c}\bold{F}_{i,c}+\beta_{i,c}$ì„ ìˆ˜í–‰í•˜ì—¬ conditioningì„ ìˆ˜í–‰í•œë‹¤.

<img src="/home/dshong/git/dazory.github.io/resources/film_visual_reasoning_with_a_general_conditioning_layer/single_film_layer.png" alt="single_film_layer" style="zoom:50%;" />

ìœ„ ê·¸ë¦¼ê³¼ ê°™ì´ FiLMì€ ë‹¨ìˆœí•œ affine transformationì„ neural networkì˜ ì¤‘ê°„ ë‹¨ê³„ featuresì— ì ìš©í•œë‹¤. ì´ë•Œ affine transformationì€ ì„ì˜ì˜ ì…ë ¥ê°’(ì—¬ê¸°ì„œëŠ” questionì— í•´ë‹¹)ì— ì˜í•´ ì¡°ê±´í™”ëœë‹¤. 



êµ¬ì²´ì ìœ¼ë¡œ FiLMì€ ë‹¤ìŒê³¼ ê°™ì´ ë™ì‘í•œë‹¤:

![film_implementation](/home/dshong/git/dazory.github.io/resources/film_visual_reasoning_with_a_general_conditioning_layer/film_implementation.png)

FiLM learns functions f and h which output $\gamma_{i,c}$ and $\beta_{i,c}$ as a function of input $\bold{x}_i$:
$$
\gamma_{i,c}=f_c(\bold{x}_i), &  \beta_{i,c}=h_c(\bold{x}_i),\\
$$
where $\gamma_{i,c}$ and $\beta_{i,c}$ modulate a neural networkâ€™s activations $\bold{F}_{i,c}$, whose subscripts refer to the ith inputâ€™s cth feature of feature map, via a feature-wise affine transformation:
$$
\text{FiLM}(\bold{F}_{i,c}|\gamma_{i,c},\beta_{i,c})=\gamma_{i,c}\bold{F}_{i,c}+\beta_{i,c}.
$$


>  ğŸ“ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” í¸ì˜ë¥¼ ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì´ ì´ë¦„ ë¶™ì˜€ë‹¤.
>
> - FiLM generator: $(\bold{\gamma}, \bold{\beta})$ë¥¼ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜ $f$ ì™€ $h$ë¥¼ í¬í•¨. 
>   â€» íš¨ìœ¨ì„ ìœ„í•´ì„œ $f$ì™€ $h$ê°€ íŒŒë¼ë¯¸í„°ë¥¼ ê³µìœ í•˜ë„ë¡ ì„¤ê³„ë„ ê°€ëŠ¥ â€»
>   - í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ë©´ $\gamma$ì™€ $\beta$ë¥¼ ì¶œë ¥í•¨
> - FiLM-ed network: FiLM layersê°€ ì ìš©ë  ë„¤íŠ¸ì›Œí¬. ì—¬ê¸°ì„œ FiLM layersëŠ” feature mapsì´ modulatedë˜ë„ë¡ í•´ì£¼ëŠ” ì—­í• ì„ í•¨.
>   - ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ì¡°ê±´ì„ ì…ë ¥í•˜ë©´ ë‹µë³€(text)ì´ ì¶œë ¥ë¨



### FiLM generator

> ìì„¸í•œ êµ¬í˜„ ì½”ë“œëŠ” ì•„ë˜ [Implementation/FiLM generator] ì„¹ì…˜ì—ì„œ í™•ì¸

FiLM generatorëŠ” $\gamma$ì™€ $\beta$ë¥¼ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜ $f$ì™€ $h$ë¡œ êµ¬ì„±ëœë‹¤. 

![film_generator](/home/dshong/git/dazory.github.io/resources/film_visual_reasoning_with_a_general_conditioning_layer/film_generator.png)

[tokenize+encoding with vocab]ëœ questions_varë¡œë¶€í„° [Embedding, GRU, Linear]ë¥¼ ì´ìš©í•˜ì—¬ question embedding($\gamma, \beta\in\mathbb{R}^{N\times4\times128}$)ì„ ìƒì„±í•œë‹¤. ì—¬ê¸°ì„œ $f$ì™€ $h$ëŠ” neural networksì™€ ê°™ì€ ì„ì˜ì˜ í•¨ìˆ˜ê°€ ë  ìˆ˜ ìˆë‹¤. 

1. ì…ë ¥: x (N, T) â† `questions_var`
   - `torch.autograd.Variable` í´ë˜ìŠ¤ëŠ” ê°’(`data` ), ë¯¸ë¶„(`grad`), backwardë¥¼ í†µí•œ ë¯¸ë¶„ì„ ê³„ì‚°í•œ í•¨ìˆ˜(`grad_fn` )ë¥¼ í¬í•¨í•œë‹¤.
2. ì¸ì½”ë”©: x â†’[Embedding]â†’ embed (N, D=100) â†’[GRU]â†’ encoded (N, hidden_size=512) Questionsì„ embeddingí•˜ì—¬ ì •ìˆ˜í˜•íƒœë¡œ ë§Œë“  ë’¤, GRU ë„¤íŠ¸ì›Œí¬ì— ì…ë ¥í•˜ì—¬ ì¸ì½”ë”©ì‹œí‚´
   - **Embedding**: tokens, e.g. Are, there, more, cubes, than, yellow, things,ì„ embeddingí•¨. i.e. ê° ë‹¨ì–´ì— ê³ ìœ í•œ ì •ìˆ˜ë¥¼ ë§µí•‘í•¨.
   - **GRU**: ì‹œê³„ì—´ ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•œ ë„¤íŠ¸ì›Œí¬. Question embeddingë¥¼ final hidden stateë¡œ ì¶œë ¥.
3. ë””ì½”ë”©: encoded â†’[Linear]â†’ film (N, num_modules * V_out = 4*256) ì¸ì½”ë”©ëœ question embeddingì„ Linear layerì— í†µê³¼ì‹œì¼œ conditioningì„ ìœ„í•œ ì„ë² ë”© ìƒì„±
4. Reshape: film â†’[Reshape]â†’ film (N, num_modules=4, V_out=256)

> ğŸª¨: ì—¬ê¸°ì„œ `num_modules` ì€ $\gamma$, $\beta$ë¥¼ ì´ìš©í•˜ì—¬ affine transformationì„ ìˆ˜í–‰í•  ResBlockì˜ ê°œìˆ˜ë¥¼ ì˜ë¯¸í•¨. `V_out` ì€ ê° ResBlockì˜ channelsì„ ì˜ë¯¸í•¨. i.e. ëª¨ë“  ResBlockì— ëŒ€í•´ì„œ, ê° channelë³„ ì¶œë ¥ $\bold{F}_{i,c}\in\mathbb{R}^{h*w}$ì— ëŒ€í•´ affine transformation $\gamma_{i,c}\bold{F}_{i,c}+\beta_{i,c}$ì„ ìˆ˜í–‰í•˜ëŠ” ê²ƒì„.



### FiLMed network

> ìì„¸í•œ êµ¬í˜„ ì½”ë“œëŠ” ì•„ë˜ [Implementation/FiLMed network] ì„¹ì…˜ì—ì„œ í™•ì¸

ìƒì„±ëœ question embedding($\gamma, \beta\in\mathbb{R}^{N\times\verb|num_modules|\times C}$)ì„ ì´ìš©í•˜ì—¬ imageë¡œë¶€í„° ì–»ì–´ì§„ features $\bold{F}\in\mathbb{R}^{N\times C\times H\times W}$ì˜ ê° ì…ë ¥ ë³„ ì±„ë„ $\bold{F}_{i,c}\in\mathbb{R}^{H\times W}$ì— ëŒ€í•´ affine transformation $\gamma_{i,c}\bold{F}_{i,c}+\beta_{i,c}$ì„ $\verb|num_modules|$ë²ˆ ìˆ˜í–‰. ì–»ì–´ì§„ ê²°ê³¼ë¥¼ classifierì— í†µê³¼ì‹œì¼œ ìµœì¢…ì ì¸ ê²°ê³¼ answer$\in\mathbb{R}^{N\times\verb|num_answers|}$ë¥¼ ì¶œë ¥.

![filmed_network](/home/dshong/git/dazory.github.io/resources/film_visual_reasoning_with_a_general_conditioning_layer/filmed_network.png)

1. ì´ë¯¸ì§€ë¥¼ CNN (Conv2d+BN+ReLU)ì— í†µê³¼ì‹œì¼œ feats $\bold{F}\in\mathbb{R}^{N\times 128\times 7*7}$ì„ ì¶œë ¥
2. featsë¥¼ FiLMedResBlockì— ì…ë ¥ì‹œì¼œì„œ ì•„ë˜ì˜ affine transformationì„ ìˆ˜í–‰:
   
    $$
    \text{FiLM}(\bold{F}_{i,c}|\gamma_{i,c},\beta_{i,c})=\gamma_{i,c}\bold{F}_{i,c}+\beta_{i,c}.
    $$
    
3. FiLMedResBlockì˜ ì¶œë ¥ì„ classifierì— í†µê³¼ì‹œì¼œì„œ answer $\verb|out|\in\mathbb{R}^{N\times\verb|num_answers|}$ë¥¼ ì¶œë ¥, 
where classifier=(Conv2d+BN+ReLU+MaxPool2d+Flatten+Linear+BN+ReLU+Linear)



### Summary


ì¦‰, í•œë§ˆë””ë¡œ ìš”ì•½í•˜ìë©´â€¦

$i$ë²ˆì§¸ ì…ë ¥ì˜ $c$ë²ˆì§¸ feature mapì— ëŒ€í•´, FiLMì€ ë‘ ê°œì˜ íŒŒë¼ë¯¸í„° $\gamma_{i,c}$ì™€ $\beta_{i,c}$ë¥¼ ì´ìš©í•˜ì—¬ feature mapì„ ë‹¤ìŒê³¼ ê°™ì´ affine transformation í•œë‹¤:

$$
\text{FiLM}(\bold{F}_{i,c}|\gamma_{i,c},\beta_{i,c})=\gamma_{i,c}\bold{F}_{i,c}+\beta_{i,c}.
$$

ì—¬ê¸°ì„œ..!

- ì´ëŸ¬í•œ conditioningì€ ë™ì¼í•œ ì…ë ¥ì— ëŒ€í•´ì„œë„ ìˆ˜í–‰í•  ìˆ˜ ìˆê³ , ë‹¤ë¥¸ ì…ë ¥ì— ëŒ€í•´ì„œë„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŒ. ì—¬ê¸°ì„œëŠ” ë‹¤ë¥¸ ì…ë ¥(questions, image)ì— ëŒ€í•´ ìˆ˜í–‰í•œ ê²°ê³¼ë§Œì„ ì œì‹œí•˜ì˜€ìŒ.

  ![other_input](/home/dshong/git/dazory.github.io/resources/film_visual_reasoning_with_a_general_conditioning_layer/other_input.png)
  

- FiLMì€ modulated feature map ë‹¹ **ë‹¨ì§€ ë‘ ê°œì˜ íŒŒë¼ë¯¸í„°ë§Œì„ í•„ìš”**ë¡œí•˜ë¯€ë¡œ, **scalable & computationally efficient** conditioning methodì´ë‹¤. ë˜í•œ, ì´ë¯¸ì§€ì˜ í•´ìƒë„ì— ë”°ë¼ scaleë˜ì§€ ì•ŠìŒ!! (ì™œëƒë©´ feature-map ë‹¹ì´ë‹ˆê¹Œâ€¦)

  ë³´ë©´, imageë¡œë¶€í„° ì–»ì–´ì§„ features $\bold{F}\in\mathbb{R}^{N\times C\times H\times W}$ì˜ ê° ì…ë ¥ ë³„ ì±„ë„ $\bold{F}_{i,c}\in\mathbb{R}^{H\times W}$ì— ëŒ€í•´ affine transformation $\gamma_{i,c}\bold{F}_{i,c}+\beta_{i,c}$ì„ $\verb|num_modules|$ë²ˆ ìˆ˜í–‰í•¨. ì¦‰, spatial dimension $H\times W$ì— ëŒ€í•´ì„œ ë™ì¼í•œ $\gamma,\beta$ê°€ ì ìš©ë¨. i.e. FiLMì€ ì…ë ¥ ì´ë¯¸ì§€ì˜ í¬ê¸°ì— ë¬´ê´€!



## Analysis

### FiLMì—ì„œ $\gamma$ì™€ $\beta$ê°€ ì–´ë–»ê²Œ feature mapì— ì˜í–¥ì„ ë¯¸ì¹ ê¹Œ?

![film_parater_histogram](/home/dshong/git/dazory.github.io/resources/film_visual_reasoning_with_a_general_conditioning_layer/film_parameter_histogram.png)

![img](/home/dshong/git/dazory.github.io/resources/film_visual_reasoning_with_a_general_conditioning_layer/figure_5.png)

$$ \gamma\bold{F}+\beta $$

- $\gamma$:

  ![img](/home/dshong/git/dazory.github.io/resources/film_visual_reasoning_with_a_general_conditioning_layer/figure_5_gamma.png)

  - 0ì—ì„œ ê°€ì¥ ë†’ì€ ë¹ˆë„:

    - Question embedding $\gamma$ë¥¼ ì´ìš©í•˜ì—¬ feature map ì „ì²´ë¥¼ í¬ê²Œ ì–µì œí•˜ëŠ” ë°©ë²•ì„ í•™ìŠµí•¨
    - ë†’ì€ í¬ê¸°ì˜ $\gamma$ê°’ì„ ê°–ëŠ” feature map $\bold{F}_{i,c}$ì— ëŒ€í•´ì„œëŠ” ì„ íƒì ìœ¼ë¡œ ìƒí–¥ì¡°ì ˆì„ í•¨

  - $\gamma$ì˜ 36%ëŠ” ìŒìˆ˜ì„:

    - FiLM ë’¤ì—ì„œ ë°”ë¡œ ReLUë¥¼ ìˆ˜í–‰í•¨.

      ![img](/home/dshong/git/dazory.github.io/resources/film_visual_reasoning_with_a_general_conditioning_layer/relu.png)

      ![img](/home/dshong/git/dazory.github.io/resources/film_visual_reasoning_with_a_general_conditioning_layer/filmed_network_relu.png)

    - ì¦‰, $\gamma<0$ì¸ ë¶€ë¶„ì€ ReLUë¥¼ í†µê³¼í•˜ë©´ì„œ  $\gamma>0$ì¸ ë¶€ë¶„ê³¼ ìƒë‹¹íˆ ë‹¤ë¥¸ activation setì„ ì¶œë ¥í•˜ê²Œ ë¨.

- $\beta$:

  ![img](/home/dshong/git/dazory.github.io/resources/film_visual_reasoning_with_a_general_conditioning_layer/figure_5_beta.png)

  - $\beta$ì˜ 76%ëŠ” ìŒìˆ˜ë¥¼ ê°€ì§
    - $\gamma$ì™€ ë§ˆì°¬ê°€ì§€ë¡œ FiLM ë’¤ì—ìˆëŠ” ReLUë¥¼ í†µê³¼í•˜ë©´ì„œ ì–´ë–¤ activationsì„ í†µê³¼ì‹œí‚¬ì§€ë¥¼ ê²°ì •í•˜ê²Œ ë¨



### FiLMì—ì„œ $\gamma$ì™€ $\beta$ ì¤‘ ë­ê°€ ë” ì¤‘ìš”í•œ ìš”ì†Œì¼ê¹Œ?

![img](/home/dshong/git/dazory.github.io/resources/film_visual_reasoning_with_a_general_conditioning_layer/figure_7.png)

- $\beta=\beta_{mean}$ê³¼ $\gamma=\gamma_{mean}$ì„ í†µí•´ í•™ìŠµ ë°ì´í„° ì „ì²´ì— ëŒ€í•œ í‰ê· ìœ¼ë¡œ ëŒ€ì²´í•´ì„œ ì¶”ë¡ í•´ë´¤ìŒ. ì´ë ‡ê²Œ í•´ì„œ testí–ˆì„ ë•Œ, $\beta=\beta_{mean}$ëŠ” ì„±ëŠ¥ì´ 1.0%ë§Œ ê°ì†Œí–ˆì§€ë§Œ, $\gamma=\gamma_{mean}$ëŠ” ì„±ëŠ¥ì´ 65.4%ë‚˜ ê°ì†Œí–ˆìŒ
- $\gamma,\beta$ì— Gaussian Noiseë¥¼ ì¶”ê°€í•´ë³´ì•˜ìŒ. $\beta$ë³´ë‹¤ $\gamma$ê°€ ì†ìƒë  ë•Œ ë”ìš± í¬ê²Œ ì„±ëŠ¥ì´ ê°ì†Œí•¨.

ì´ ë‘ ê²°ê³¼ëŠ” ëª¨ë‘, FiLMì—ì„œ $\beta$ë³´ë‹¤ $\gamma$ê°’ì´ ë” ì¤‘ìš”í•¨ì„ ì˜ë¯¸í•¨.



### FiLMì„ ì–´ë–»ê²Œ ë””ìì¸í–ˆì„ ë•Œ ì˜ conditioningí•  ìˆ˜ ìˆì„ê¹Œ?

![img](/home/dshong/git/dazory.github.io/resources/film_visual_reasoning_with_a_general_conditioning_layer/restricted_gamma.png)

- $\gamma$ì™€ $\beta$ ì¤‘ í•˜ë‚˜ë¥¼ ìƒìˆ˜ë¡œ ê³ ì •í•´ì„œ í•™ìŠµ ì‹œì¼œë³´ì•˜ìŒ â‡’ $\gamma$ê°€ $\beta$ë³´ë‹¤ ì¤‘ìš”í•¨

- $\gamma$ê°’ì˜ ë²”ìœ„ë¥¼ ì œí•œë‘ì–´ì„œ í•™ìŠµ ì‹œì¼œ ë³´ì•˜ìŒ

  : $\sigma(\gamma)\in(0,1)$;  $tanh(\gamma)\in(-1,1)$;  $\exp(\gamma)\in(0,\infin)$;

  - $\sigma(\gamma)\in(0,1)$ & $tanh(\gamma)\in(-1,1)$:

    $\gamma=1$ë¡œ í•™ìŠµí•˜ëŠ” ê²ƒ ë§Œí¼ì´ë‚˜ ì„±ëŠ¥ì„ í•˜ë½ì‹œí‚´. i.e. í° $\gamma$ê°’ì„ í†µí•´ feature mapì„ í° ê·œëª¨ë¡œ í™•ì¥ì‹œí‚¤ëŠ” ê²ƒì´ ì¤‘ìš”í•¨.

  - $\exp(\gamma)\in(0,\infin)$:

    $\gamma$ê°€ ìŒìˆ˜ë‚˜ 0ì˜ ê°’ì„ ê°–ëŠ” ê²ƒì€ ë§¤ìš° ì¤‘ìš”.

  > ğŸª¨ ìš”ì•½í•˜ìë©´, conditioningì„ ì˜í•˜ê¸° ìœ„í•´ì„œ (1) $\gamma$ëŠ” í° ê·œëª¨ì˜ ê°’ì„ ê°€ì ¸ì•¼ í•˜ë©° (2) ìŒìˆ˜ë‚˜ 0ì˜ ê°’ì„ ê°€ì ¸ì•¼ í•œë‹¤.



### FiLMì„ ResBlockì—ì„œ ë‹¤ë¥¸ ìœ„ì¹˜ì— ë‘ì—ˆì„ ë•Œ ì–´ë–¤ ì˜í–¥ì´ ìˆì„ê¹Œ?

![image-20240209182726098](/home/dshong/git/dazory.github.io/resources/film_visual_reasoning_with_a_general_conditioning_layer/moving_film.png)

- ì—¬ê¸°ì„œ í¬ì¸íŠ¸ëŠ” FiLMì„ BNì˜ ì•ì— ë‘ë˜ ë’¤ì— ë‘ë˜, ReLUì˜ ì•ì— ë‘ë˜ ë’¤ì— ë‘ë˜, ì„±ëŠ¥ì— í° ì˜í–¥ ì—†ìŒ

  <img src="/home/dshong/git/dazory.github.io/resources/film_visual_reasoning_with_a_general_conditioning_layer/filmed_network_relu.png" alt="img" style="zoom:50%;" />

  - Best architecture â†’[Conv]â€”$\cdot$â†’[ReLU]â†’[Conv]â†’[BN]â†’**[FiLM]**â†’[ReLU]â†’(+)â†’
  - FiLM after residual connection â†’[Conv]â€”$\cdot$â†’[ReLU]â†’[Conv]â†’[BN]â†’[ReLU]â†’(+)â†’**[FiLM]**â†’
  - FiLM after ResBlock ReLU-2 â† ê±°ì˜ ë¹„ìŠ·í•œ ì„±ëŠ¥ â†’[Conv]â€”$\cdot$â†’[ReLU]â†’[Conv]â†’[BN]â†’[ReLU]â†’**[FiLM]**â†’(+)â†’
  - FiLM after ResBlock Conv-2 â† ê±°ì˜ ë¹„ìŠ·í•œ ì„±ëŠ¥ â†’[Conv]â€”$\cdot$â†’[ReLU]â†’[Conv]â†’**[FiLM]**â†’[BN]â†’[ReLU]â†’(+)â†’
  - FiLM before ResBlock Conv-1 â† ì„±ëŠ¥í•˜ë½ ìˆìŒ â†’**[FiLM]**â†’[Conv]â€”$\cdot$â†’[ReLU]â†’[Conv]â†’[BN]â†’[ReLU]â†’(+)â†’
  - ì¦‰, FiLMì€ BNì— ëŒ€í•´ ì˜ì¡´í•˜ëŠ” ê²ƒì²˜ëŸ¼ ë³´ì´ì§„ ì•ŠìŒ. ë”°ë¼ì„œ BNì„ ì“°ì§€ ì•ŠëŠ” ë‹¤ë¥¸ ë„¤íŠ¸ì›Œí¬, e.g. LayerNormì„ ì“°ëŠ” ê²½ìš°,ì—ì„œë„ ì‚¬ìš©í•  ìˆ˜ ìˆì„ ê²ƒì´ë‹¤!



### Modulesì— FiLMì„ ëª‡ ë²ˆ ì ìš©í•˜ëŠ”ì§€ê°€ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥?

![image-20240209182923156](/home/dshong/git/dazory.github.io/resources/film_visual_reasoning_with_a_general_conditioning_layer/removing_film.png)

- í•˜ë‚˜ë¼ë„ FiLMì´ ìˆìœ¼ë©´ ë¨: `No FiLM in ResBlock 2-4`  vs. `No FiLM in ResBlock 1-4`



### Modulesì˜ ê°œìˆ˜ê°€ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥?

![image-20240209183029702](/home/dshong/git/dazory.github.io/resources/film_visual_reasoning_with_a_general_conditioning_layer/num_modules.png)

í•œê°œë§Œ ì•„ë‹˜ ë¨.



### ì•„í‚¤í…ì²˜ê°€ ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥?

![image-20240209183112852](/home/dshong/git/dazory.github.io/resources/film_visual_reasoning_with_a_general_conditioning_layer/miscellanenous.png)

- Residual connectionì´ ì—†ìœ¼ë©´ ì„±ëŠ¥ì´ í¬ê²Œ ê°ì†Œí•¨. Global max-poolingì„ ë§ˆì§€ë§‰ì— ì“°ëŠ”ë°, ê·¸ë•Œ ë‚®ì€ ìˆ˜ì¤€ê³¼ ë†’ì€ ìˆ˜ì¤€ì˜ ì¶”ë¡ ì„ í†µí•´ ë°˜ë³µì ìœ¼ë¡œ ì¤‘ìš”í•œ ìœ„ì¹˜ì˜ íŠ¹ì§•ì„ ì‚¬ìš©í•˜ì—¬ ìµœì¢… ê²°ì •ì„ ë‚´ë¦¼ì„ ì‹œì‚¬. i.e. Residual ì•ˆì“°ë©´ ë‚®ì€ ìˆ˜ì¤€ì—ì„œì˜ ê²°ê³¼ì˜ ì˜í–¥ì´ ì‘ì•„ì§€ëŠ”ë°, ê·¸ëŸ¬ë©´ ìƒëŒ€ì ìœ¼ë¡œ ë†’ì€ ìˆ˜ì¤€ì˜ ê²°ê³¼ë§Œ ì‚¬ìš©í•˜ê²Œ ë¨. Residualì„ ì“´ë‹¤ëŠ” ê²ƒì€ ë‚®ì€ ìˆ˜ì¤€ì˜ ê²°ê³¼ì™€ ë†’ì€ ìˆ˜ì¤€ì˜ ê²°ê³¼ë¥¼ í•¨ê»˜ ì‚¬ìš©í•˜ì—¬ ì¶”ë¡ í•¨ì„ ì˜ë¯¸.

  ![img](/home/dshong/git/dazory.github.io/resources/film_visual_reasoning_with_a_general_conditioning_layer/tsne_film.png)

  > ğŸª¨ Global max-pooling:Ablation
  >
  > ![img](/home/dshong/git/dazory.github.io/resources/film_visual_reasoning_with_a_general_conditioning_layer/global_averaging_pooling.png)



### ì „ì²´ì ìœ¼ë¡œ ìš”ì•½í•˜ìë©´â€¦

1. Conditioningì— ì¤‘ìš”í•œ ê±´ $\beta$ë³´ë‹¨ $\gamma$.
   - ì´ë•Œ $\gamma$ëŠ” í° ê·œëª¨ì˜ ê°’ì„ ê°€ì§€ë©° negativeê°’ì„ ê°€ì§ˆ ìˆ˜ ìˆì„ ë•Œ ì„±ëŠ¥ì´ ë” ì¢‹ìŒ. â‡’ í° ê·œëª¨ì˜ ê°’ì„ í†µí•´ feature mapì—ì„œ ì¤‘ìš”ë„ë¥¼ scalingí•˜ê³ , negative ê°’ì„ í†µí•´ activationì—ì„œ ì„œë¡œ ë‹¤ë¥¸ ì˜í–¥ì„ ë§Œë“¤ì–´ë‚´ê¸° ë•Œë¬¸ìœ¼ë¡œ í•´ì„ ê°€ëŠ¥
2. FiLM ì•ˆì“°ë©´ conditioning ì„±ëŠ¥ í¬ê²Œ ë–¨ì–´ì§. ëª‡ ê°œë¥¼ ì“°ë“  í¬ê²Œ ìƒê´€ ì—†ì§€ë§Œ ì ì–´ë„ í•˜ë‚˜ëŠ” ì¨ì•¼ í•¨.
3. Residual connectionì„ ì‚¬ìš©í•´ì•¼ lowerâ†’higher ì „ë°˜ì ì¸ featuresë¥¼ ëª¨ë‘ ì´ìš©í•˜ì—¬ ë³´ë‹¤ ë³µí•©ì ì¸ ì¶”ë¡ ì´ ê°€ëŠ¥í•´ì§€ëŠ” ê²ƒìœ¼ë¡œ ë³´ì„.



## When?

- ì£¼ì–´ì§„ ì…ë ¥(e.g. image)ì„ ì„ì˜ì˜ ì…ë ¥(e.g. question)ì„ ì´ìš©í•˜ì—¬ conditioningí•˜ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ.

  ![other_input](/home/dshong/git/dazory.github.io/resources/film_visual_reasoning_with_a_general_conditioning_layer/other_input.png)

  - E.g. image stylization: ì£¼ì–´ì§„ ì…ë ¥ì´ content image, ì„ì˜ì˜ ì…ë ¥ì´ style imageì¸ ê²½ìš°

    [[ì°¸ê³ ](https://github.com/ndb796/Deep-Learning-Paper-Review-and-Practice/blob/master/code_practices/AdaIN_Style_Transfer_Tutorial.ipynb)]

    ![image-20240209183435478](/home/dshong/git/dazory.github.io/resources/film_visual_reasoning_with_a_general_conditioning_layer/image_stylization.png)

    ì •ê·œí™”ëœ ì£¼ì–´ì§„ ì…ë ¥ $x$ (=$\frac{x-\mu(x)}{\sigma(x)}$)ì„ ì„ì˜ì˜ ì…ë ¥ $y$(=style input)ë¥¼ ì´ìš©í•˜ì—¬ affine transformation $\sigma\bar{x}+\mu$ì„ ìˆ˜í–‰

    - ì—¬ê¸°ì„œ $\bar{x}\in\mathbb{R}^{1\times 512\times 64\times 86}$; $y\in\mathbb{R}^{1\times 512\times 64\times 86}$; $\sigma(y)\in\mathbb{R}^{1\times 512\times1\times1}$; $\mu(y)\in\mathbb{R}^{1\times 512\times1\times1}$

      - $x$

        ![image-20240209183539439](/home/dshong/git/dazory.github.io/resources/film_visual_reasoning_with_a_general_conditioning_layer/image_stylization_x.png)

      - $y$

        ![image-20240209183630780](/home/dshong/git/dazory.github.io/resources/film_visual_reasoning_with_a_general_conditioning_layer/image_stylization_y.png)

    FiLMê³¼ ê±°ì˜ ìœ ì‚¬. ê° ì…ë ¥ì— ëŒ€í•´ channelë³„ë¡œ ë™ì¼í•œ gamma(=$\sigma(y)$)ì™€ beta(=$\mu(y)$)ë¥¼ ì´ìš©í•˜ì—¬ affine transformationí•˜ëŠ” ê²ƒì„. ë‹¤ë¥¸ ì ì´ ìˆë‹¤ë©´, AdaINì€ mean, stdë¥¼ ì´ìš©í•˜ì—¬ gamma, betaë¥¼ ê³„ì‚°í•˜ê³ , FiLMì€ ì–´ë– í•œ í•¨ìˆ˜($f,h$)ë¥¼ ì´ìš©í•˜ì—¬ gamma, betaë¥¼ ê³„ì‚°í•œë‹¤ëŠ” ê²ƒì„. ì¦‰, FiLMì´ AdaINì˜ ë”ìš± ì¼ë°˜í™”ëœ ë²„ì „ì´ê¸´ í•¨.



## If?

- Simple: ì ìš©í•˜ê¸° ì•„ì£¼ ì‰½ê¸´ í•¨. ê·¸ë¦¬ê³  ì¼ë°˜í™”ëœ ë°©ë²•ë¡ ì´ë¼ ì–´ë–¤ ì…ë ¥ì´ë“  ì „ë¶€ ë‹¤ ì ìš© ê°€ëŠ¥.

- Effective

  - Ablationsì™€ ì•„í‚¤í…ì²˜ ìˆ˜ì •ì— ëŒ€í•´ ê°•ì¸í•œ ì„±ëŠ¥ì„ ë³´ì„: ì•„í‚¤í…ì²˜ ì¡°ê¸ˆ ìˆ˜ì •í•œë‹¤ê³  ì„±ëŠ¥ì´ í¬ê²Œ í•˜ë½ë˜ì§„ ì•ŠìŒ.

    ![image-20240209183734397](/home/dshong/.config/Typora/typora-user-images/image-20240209183734397.png)

  - ì•„ì£¼ ì ì€ ì˜ˆì‹œì˜ ìƒˆë¡œìš´ ë°ì´í„°ë‚˜ zero-shotê³¼ ê°™ì€ ë¬¸ì œì— ëŒ€í•´ ì˜ ì¼ë°˜í™”ë¨

    ![img](/home/dshong/git/dazory.github.io/resources/film_visual_reasoning_with_a_general_conditioning_layer/illustration.png)

    CLEVR-CoGenTëŠ” ì¼ë°˜í™” ëŠ¥ë ¥ì„ ë³´ê¸° ìœ„í•œ benchmark

    - A: ëª¨ë“  cubeê°€ [gray/blue/brown/yellow]; ëª¨ë“  cylinderê°€ [red/green/purple/cyan]
    - B: ëª¨ë“  cylinderê°€ [gray/blue/brown/yellow]; ëª¨ë“  cubeê°€ [red/green/purple/cyan]

    Aì—ì„œ í•™ìŠµí•˜ê³  Bì—ì„œ testë¥¼ ìˆ˜í–‰. ì´ë¥¼ í†µí•´ ë„¤íŠ¸ì›Œí¬ê°€ ì–¼ë§ˆë‚˜ biasë˜ì—ˆëŠ”ì§€ í™•ì¸ ê°€ëŠ¥.

    ![img](/home/dshong/git/dazory.github.io/resources/film_visual_reasoning_with_a_general_conditioning_layer/figure_9.png)

    ì œì¼ ì„±ëŠ¥ ì¢‹ìŒ. ì‚¬ì‹¤ biasê°€ ì•„ì˜ˆ ì•ˆë¼ê¸°ëŠ” ì‰½ì§€ ì•Šì§€ë§Œ, ì–´ì¨‹ë“  ì¢€ ëœ biasë˜ì—ˆë‹¤ëŠ” ê±¸ ë³´ì—¬ì¤Œ.

- Scalable & Computational efficient

  - Modulated feature map ë‹¹ ë‹¨ì§€ ë‘ ê°œì˜ íŒŒë¼ë¯¸í„° $\gamma$ & $\beta$ë§Œì„ í•„ìš”ë¡œ í•œë‹¤ â‡’ scalable!!
  - ì´ë¯¸ì§€ì˜ í•´ìƒë„ì— ë”°ë¼ scaleë˜ì§€ ì•ŠëŠ”ë‹¤. ($\because$ feature-map ë‹¹ íŒŒë¼ë¯¸í„°ë¥¼ í•„ìš”ë¡œ í•˜ë¯€ë¡œ)



## Takeaways

1. ì„ì˜ì˜ ì…ë ¥ì— ëŒ€í•´ conditioningí•˜ê³ ì‹¶ì„ ë•Œ ê°„ë‹¨í•˜ê²Œ ê°€ì ¸ë‹¤ê°€ ì“°ê¸° ì¢‹ì•„ë³´ì„. simple & robust & scalableí•´ì„œ..!
   1. ì—­ì‹œ ê°€ì ¸ë‹¤ ì“°ê¸° í¸í•œê²Œ ì œì¼ì´ë‹¤..!
2. ë¶„ì„ì„ ì¢€ ì˜í•œë“¯. Ablation studyë„ ê¸€ì½” t-SNEë„ ê¸€ì½”.. ì£¼ì¥í•˜ëŠ” ë°”ê°€ ì‹¤í—˜ìœ¼ë¡œ ì˜ ë³´ì—¬ì„œ ì½ìœ¼ë©´ ëŒ€ë¶€ë¶„ ë‚©ë“ì´ ë¨.
3. ì‚¬ì‹¤ í¬ê²Œ ìƒˆë¡œìš´ ë‚´ìš©ì€ ì—†ëŠ”ë“¯..ã…ã……ã…;
   1. ë‚˜ì¤‘ì— ê°€ì ¸ë‹¤ ì“°ë ¤ë©´ ê¸°ìˆ ì ì¸ ë¶€ë¶„, e.g. residual connectionì˜ ì—­í• , $\gamma$ì˜ ë””ìì¸ ì´ˆì´ìŠ¤, etc,ì„ ì˜ ê¸°ì–µí–ˆë‹¤ê°€ í™œìš©í•˜ëŠ” ê±´ ì¢‹ì„ë“¯.



## Implementation

### FiLM generator

```python
# scripts/train_model.py
from torch.autograd import Variable

# Set up model
program_generator = FiLMGen(...)
pg_optimizer = optim_method(program_generator.parameters(), ...)

execution_engine = FiLMedNet(...)
ee_optimizer = optim_method(execution_engine.parameters(), ...)

for _ in range(epochs):
	for batch in train_loader:
		questions, _, feats, answers, programs, _ = batch
		# questions = {Tensor: (bs, max_questions_length)=(64, 46)}
		# fest = {Tensor: (bs, c, h, w) = (64, 1024, 14, 14)}
		# answers = {Tensor: (bs,) = (64,)} <- ground-truthë¡œ ì‚¬ìš©ë¨
		# programs = {Tensor: (bs, max_programs_length) = (64, 27)} <- filmì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ.

		questions_var = Variable(questions.cuda())
		feats_var = Variable(feats.cuda()) 
    answers_var = Variable(answers.cuda()) 
		programs_var = Variable(programs.cuda())
 
		# program_generator = FiLM(): encoded questionì„ ì…ë ¥í•˜ì—¬ gamma, betaë¥¼ ì¶œë ¥
		film = program_generator(questions_var)
		# execution_engine = FiLMedNet(): ì´ë¯¸ì§€ë¡œë¶€í„° features Fë¥¼ ì¶œë ¥í•˜ê³ , ì´ë¥¼ gammaì™€ betaë¥¼ ì´ìš©í•˜ì—¬ conditioning
		scores = execution_engine(feats_var, film) 
		# scores = (bs, num_answers) = (64, 32)
		
		loss = torch.nn.CrossEntropyLoss()(scores, answers_var)
				
		pg_optimizer.zero_grad()
		ee_optimizer.zero_grad()
		loss.backward()
```





### FiLMed network

```python
# scripts/train_model.py
from torch.autograd import Variable

# Set up model
program_generator = FiLMGen(...)
****pg_optimizer = optim_method(program_generator.parameters(), ...)

**execution_engine = FiLMedNet(...)**
ee_optimizer = optim_method(execution_engine.parameters(), ...)

for _ in range(epochs):
	for batch in train_loader:
		questions, _, feats, answers, programs, _ = batch
		questions_var = Variable(questions.cuda())
		film = program_generator(questions_var)
		scores = **execution_engine**(feats_var, film) # FiLMedNet()
		
		loss = loss_fn(scores, answers_var)
				
		pg_optimizer.zero_grad()
		ee_optimizer.zero_grad()
		loss.backward()

# vr/models/filmed_net.py
class FiLMedNet(nn.Module):
		def forward(self, x, film):
				# x = feats = (N, ??, module_H, module_W)
				# film = (N, num_modules, V_out) = (N, 4, 256)

				# Prepare FiLM layers
				gammas, betas = torch.split(film[:, :, :2*module_dim], self.module_dim, dim=-1)
				# gammas = (N, num_modules=4, module_dim=128)
				# betas = (N, num_modules=4, module_dim=128)
```

1. Prepare FiLM layers: film â†’ $\gamma\in\mathbb{R}^{N\times 4\times 128}$, $\beta\in\mathbb{R}^{N\times 4\times 128}$

   ```python
   				# Propagate up image features CNN
   				batch_coords = self.coords.unsqueeze(0).expand(torch.Size((x.size(0), *self.coords.size())))
   				x = torch.cat([x, batch_coords], 1)
   				# x = (N, ?? + 2, 7, 7)
   				
   				# self.stem = [Conv2d(feature_dim=2048, module_dim=128, kernel_size=3, stride=1, padding=1), BN(module_dim=128), ReLU]
   				# x = (N, ?? + 2, 7, 7) = (N, 2048, 7, 7)
   				feats = self.stem(x)
   				# feats = [N, 128, 7, 7]
   				N, _, H, W = feats.size()
   ```

2. Propagate up image features CNN: x â†’[Conv2d, BN, ReLU]â†’ feats (N, 128, 7, 7)

   ![img](/home/dshong/git/dazory.github.io/resources/film_visual_reasoning_with_a_general_conditioning_layer/img.png)

   ì´ë¯¸ì§€ë¡œ ë¶€í„° features ì¶œë ¥

   ```python
   				# Propagate up the network from low-to-high numbered blocks
   				feats1 = self.**function_modules**[0](feats, gammas[:,0,:], betas[:,0,:], batch_coords)
   				feats2 = self.**function_modules**[1](feats1, gammas[:,1,:], betas[:,1,:], batch_coords)
   				feats3 = self.**function_modules**[2](feats2, gammas[:,2,:], betas[:,2,:], batch_coords)
   				feats4 = self.**function_modules**[3](feats3, gammas[:,3,:], betas[:,3,:], batch_coords)
   				
   				# Run the final classifier over the resultant, post-modulated features.
   				**final_module_output** = torch.cat([feats4, batch_coords], 1)
   				# self.classifier:
   				#   [Conv2d, BN, ReLU]->[maxpool]->[Flatten]->
   				#   ->[Linear]->[Linear]-> (N, num_answers)
   				out = self.**classifier**(final_module_output)
   				
   				return out
   ```

3. Propagate up the network from low-to-high numbered blocks

   ![img](/home/dshong/git/dazory.github.io/resources/film_visual_reasoning_with_a_general_conditioning_layer/film_part1.png)

   1. CNNì˜ ì¶œë ¥ì¸ featsë¥¼ ResBlockì— ì°¨ë¡€ë¡œ ì…ë ¥

      ```python
      function_modules[i] = FiLMedResBlock(...)
      ```

   2. ResBlockì˜ ì¶œë ¥ì„ Classifierì— ì…ë ¥

      ```python
      [Conv2d(module_C=(128+2)*7*7, proj_dim=512)]
      â†’[BN]â†’[ReLU]â†’ (N, proj_dim=512, 7, 7)
      â†’[maxpool2d(7)]â†’ (N, proj_dim=512)
      â†’[Flatten()]â†’ (N, proj_dim=512)
      â†’[Linear(proj_dim=512, fc_dim=1024)]â†’[BN]â†’[ReLU]
      â†’[Linear(fc_dim=1024, num_answers)]â†’ (N, num_answers)
      ```

   - `FiLMedResBlock().forward()`

     <img src="/home/dshong/git/dazory.github.io/resources/film_visual_reasoning_with_a_general_conditioning_layer/filmed_network_relu.png" alt="img" style="zoom:30%;" />

     ```python
     # vr/models/filmed_net.py
     layer_output = self.**function_modules**[fn_num](
     										module_inputs[:, fn_num], # x
     										gammas[:, fn_num, :], # gammas
     										betas[:, fn_num, :], # betas
     										batch_coords) # extra_channels
     
     class FiLMedResBlock(nn.Module):
     		def __init__(self, in_dim=module_dim=128):
     				self.condition_method = 'bn-film'
     				self.extra_channel_freq = 1
     				self.with_input_proj = 1
     				self.with_batchnorm = 1
     				# self.condition_pattern = [1, 1, 1, 1]
     				self.with_cond = self.condition_pattern[self.module_num_layers * fn_num: self.module_num_layers * (fn_num + 1)]
     				self.input_proj = nn.Conv2d(
     						in_dim + num_extra_channels, # =128+2
     						in_dim, kernel_size=1, padding=0)
     				self.with_residual = 1
     				
     				if out_dim is None: 
     						out_dim = in_dim 
     				self.conv1 = nn.Conv2d(in_dim, out_dim, kernel_size=3, padding=1)
     				
     
     		def forward(self, x, 
     						gammas=None, betas=None, 
     						extra_channels=None, cond_maps=None):
     				# x <- feats (N, module_dim, H, W) = (N, 128, 7, 7)
     				# extra_channels <- batch_coords = (N, 2)
     				x = torch.cat([x, extra_channels], 1) 
     				# x = (N, module_dim+2, H, W) = (N, 130, 7, 7)
     				
     				# self.input_proj = Conv2d(130, 128)
     				x = F.relu(**self.input_proj**(x))
     				out = x
     				# out = (N, module_dim, H, W) = (N, 128, 7, 7)
     
     				# ResBlock body
     				out = self.conv1(out) # Conv2d(128, 128)
     				out = self.bn1(out)
     				out = self.**film**(out, gammas, betas)
     				out = F.relu(out)
     
     				# ResBlock remainder
     				if self.with_residual:
     						out = x + out
     				
     				return out
     ```







